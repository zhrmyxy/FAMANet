### Experimental fairness
æ„Ÿè°¢å®¡ç¨¿äººçš„æ„è§ï¼Œæœ¬æ–‡ä¸¥æ ¼æŒ‰ç…§äº†HSNetä»¥åŠDCAMAçš„å®éªŒæ¡ä»¶ä¸‹è¿›è¡Œï¼Œä¸ä¹‹ä¸åŒçš„æ˜¯ï¼Œæˆ‘ä»¬æ”¹å˜äº†ä¼˜åŒ–å™¨SGDï¼Œä¿®æ”¹æˆäº†Adamï¼Œå­¦ä¹ ç‡è®¾ç½®ä¸º1e-4ï¼Œè®­ç»ƒ100è½®æ¬¡å¹¶éµå¾ªHSNetåœ¨æ²¡æœ‰æ•°æ®å¢å¼ºçš„æƒ…å†µä¸‹è®­ç»ƒæˆ‘ä»¬çš„æ¨¡å‹ï¼Œç›´åˆ°æ”¶æ•›ï¼Œä»¥ä¾¿ä¸ä¹‹å‰çš„æœ€ä½³æ€§èƒ½æ–¹æ³•è¿›è¡Œå…¬å¹³çš„æ¯”è¾ƒã€‚è®­ç»ƒå’Œæ¨ç†æ˜¯åœ¨å››ä¸ªNVIDIA RTX 4090ä¸Šã€‚æˆ‘ä»¬ä¸DCAMAé‡‡ç”¨ä¸€è‡´çš„åˆ†è¾¨ç‡384*384ï¼Œä¸ºäº†ä¸Swin-Bé€‚é…ã€‚å¯¹æ¯”å®éªŒä¸­éƒ¨åˆ†é‡‡ç”¨äº†473*473åˆ†è¾¨ç‡ï¼Œæˆ‘ä»¬è¿›è¡Œç­‰é‡å®éªŒä½¿ç”¨åˆ†è¾¨ç‡ä¸º473*473ï¼Œå…¶ä»–å®éªŒæ¡ä»¶ä¿æŒä¸å˜ã€‚è®­ç»ƒè¿‡ç¨‹ä¸­473*473åˆ†è¾¨ç‡æ˜¾å­˜å ç”¨æ˜æ˜¾å¢å¤§ï¼Œå¹¶ä¸”è®­ç»ƒæ—¶é—´è¿‡é•¿ã€‚å…¶æœ€ç»ˆæ€§èƒ½ä¸384*384ç›¸æ¯”ï¼šï¼Ÿ


### Response to PAAM module
æˆ‘ä»¬ç¡®è®¤Waå’ŒWpæ˜¯é€šè¿‡ç«¯åˆ°ç«¯çš„åå‘ä¼ æ’­è‡ªé€‚åº”å­¦ä¹ å¾—åˆ°çš„ï¼Œè®¾è®¡äº†ä¸€ä¸ªè½»é‡çº§çš„å‚æ•°ç”Ÿæˆç½‘ç»œï¼Œè¯¥å­ç½‘ç»œåŒ…å«å…¨å±€å¹³å‡æ± åŒ–å±‚å’Œä¸¤å±‚MLPï¼ˆLinear -> ReLU -> Linear -> Softmaxï¼‰ã€‚

å¯¹äºå…±äº«å˜æ¢ï¼Œæˆ‘ä»¬ä½¿ç”¨çº¿æ€§å±‚è¿›è¡Œé™ç»´çš„æ—¶å€™ä½¿ç”¨äº†å…±äº«çš„çº¿æ€§å±‚ï¼Œè€Œç”Ÿæˆå„è‡ªå˜æ¢æ—¶ä½¿ç”¨ç‹¬ç«‹çš„çº¿æ€§å±‚ï¼Œå…±äº«æƒé‡é€šè¿‡å‡å°‘å‚æ•°é‡èµ·åˆ°äº†æ­£åˆ™åŒ–ä½œç”¨ï¼Œé˜²æ­¢äº†å°æ ·æœ¬ä»»åŠ¡ä¸­çš„è¿‡æ‹Ÿåˆï¼Œå¼ºåˆ¶å¹…åº¦å’Œç›¸ä½ç‰¹å¾åœ¨ç»Ÿä¸€çš„æ½œç©ºé—´ä¸­å¯¹é½ã€‚

### Cost Analysis of AMAM Calculation
AMAMæ¨¡å—æ˜¯æ— å‚æ•°çš„ï¼Œå…¶è¿ç®—ä¸»è¦æ˜¯ç”±çŸ©é˜µä¹˜æ³•å¾—åˆ°ï¼Œè®¡ç®—å¤æ‚åº¦æ˜¯Oï¼ˆN2ï¼‰
<div align="center">
  <img width="729" height="107" alt="image" src="https://github.com/user-attachments/assets/68bc429a-8520-4baf-b6c8-b9604102277a" />
</div>

å«å™ªå£°æ”¯æŒæ©ç å®éªŒï¼šä¸ºäº†è¯„ä¼°æ¨¡å‹å¯¹ä¸å®Œç¾æ ‡æ³¨çš„é²æ£’æ€§ï¼Œæˆ‘ä»¬é€šè¿‡å¯¹ æ”¯æŒ æ©ç åº”ç”¨å½¢æ€å­¦è†¨èƒ€æ¥æ¨¡æ‹Ÿå™ªå£°ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸åŒå¤§å°çš„æ ¸æ¥æ‰©å±•æ©ç è¾¹ç•Œã€‚è¿™ä¸€è¿‡ç¨‹ä¸å¯é¿å…åœ°å°†èƒŒæ™¯æ‚è´¨å¼•å…¥åˆ°æ”¯æŒç‰¹å¾ä¸­ï¼Œåˆ›é€ äº†ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„åœºæ™¯ã€‚
<div align="center">
  <img width="687" height="151" alt="image" src="https://github.com/user-attachments/assets/d1c860f0-1596-460c-95ea-789cb1352d34" />
</div>

ç”±æ­¤è¡¨å¯ä»¥çœ‹åˆ°å°±ç®—åœ¨è†¨èƒ€ç‡20æ”¯æŒæ©ç å…·æœ‰ä¸¥é‡å™ªå£°æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬çš„æ¨¡å‹ä»ç„¶ä¿æŒä¸€å®šçš„æ€§èƒ½ï¼Œè¯æ˜äº†æˆ‘ä»¬æ¨¡å‹é¢å¯¹å«å™ªå£°æ”¯æŒæ©ç çš„å®éªŒé²æ£’æ€§

### CTSGM and Generalization of the model
We followed the standard protocol by using the template "a photo of a {class}" for text embeddings. Additionally, we explicitly verified the generalization effectiveness of our method through cross-domain experiments transferred from COCO-20i to PASCAL-5i.
æœ¬æ–‡å®éªŒé‡‡ç”¨çš„æ˜¯æ ‡å‡†æ¨¡æ¿ï¼ša photo of a {class},è¿›ä¸€æ­¥æœ¬æ–‡åœ¨è·¨æ•°æ®é›†ä¸Šå®éªŒCOCO-20i to PAscal-5iéªŒè¯å…¶æ³›åŒ–æœ‰æ•ˆæ€§.


<div align="center">
  <img width="610" height="197" alt="image" src="https://github.com/user-attachments/assets/e1562c8b-da58-4333-b60a-5456b2d85937" />
</div>





# Frequency-enhanced Affinity Map Weighted Mask Aggregation for Few-Shot Semantic Segmentation

<div align="center">

<!-- You can add badges here if you have them, e.g., PyTorch version, License -->
<!-- ![PyTorch](https://img.shields.io/badge/PyTorch-%23EE4C2C.svg?style=for-the-badge&logo=PyTorch&logoColor=white) -->

</div>

## ğŸ“– Introduction

This repository contains the implementation of **Frequency-enhanced Affinity Map Weighted Mask Aggregation (FAMANet)** for Few-Shot Semantic Segmentation.

## ğŸ—ï¸ Network Architecture

The overall architecture of our proposed method is shown below:

<div align="center">
  <img width="1485" height="718" alt="Network Architecture" src="https://github.com/user-attachments/assets/0d70bd9b-b4d1-45c9-b0aa-41f1d0f80a1e" />
</div>

---

## ğŸ§© Key Modules

### 1. Phase and Amplitude Attention Module (PAAM)

PAAM is designed to enhance feature representation by utilizing frequency domain information.

- **Source Code**: The implementation of PAAM can be found in [`PhaseandAmplitudeAttention.py`](./PhaseandAmplitudeAttention.py). 

<div align="center">
  <img src="https://github.com/user-attachments/assets/0c070ff6-e029-42f0-a4ae-51cf7d82a6ef" width="700" alt="PAAM Structure">
</div>

#### Visualization of PAAM Effects
Visual comparison showing the effectiveness of the frequency-enhanced attention:

<div align="center">
  <img src="https://github.com/user-attachments/assets/292ded22-2696-48b3-a193-8cd544828303" width="600" alt="PAAM Visualization">
</div>

### 2. Affinity Map Aggregation Module (AMAM)

AMAM utilizes cross-attention mechanisms to aggregate mask weights based on affinity maps.

- **Source Code**: The implementation of AMAM can be found in [`CrossAttention.py`](./CrossAttention.py). 

<div align="center">
  <img src="https://github.com/user-attachments/assets/9a5b1505-7496-4217-952a-501e9bb5b236" width="700" alt="AMAM Structure">
</div>

---
###   DataSet
<div align="center">
  <img width="720" height="750" alt="image" src="https://github.com/user-attachments/assets/f9934672-845b-4ed1-b76d-d47d5afe33c5" />
</div>
<div align="center">
  <img width="722" height="752" alt="image" src="https://github.com/user-attachments/assets/41b72d33-ee1b-4ebb-9a3f-76b75caf60e0" />
</div>



## ğŸš€ Getting Started

### Training
To train the model, please verify the configurations in the script and run:

```bash
bash train.sh

### Testing
To test the model, please verify the configurations in the script and run:

```bash
bash test.sh

