### Experimental fairness
æ„Ÿè°¢å®¡ç¨¿äººçš„æ„è§ã€‚ä¸ºäº†æ¶ˆé™¤åˆ†è¾¨ç‡è®¾ç½®ä¸åŒå¸¦æ¥çš„å…¬å¹³æ€§æ‹…å¿§ï¼Œæˆ‘ä»¬åœ¨æœ¬é¢†åŸŸé€šç”¨çš„473Ã—473å’Œ448Ã—448åˆ†è¾¨ç‡ä¸‹è¿›è¡Œäº†ç­‰é‡å¯¹æ¯”å®éªŒã€‚å®éªŒç»“æœè¡¨æ˜FAMANetå¯¹è¾“å…¥å°ºå¯¸çš„å˜åŒ–å…·æœ‰è¾ƒå¼ºçš„é²æ£’æ€§ï¼Œä¸åŒåˆ†è¾¨ç‡ä¸‹çš„æ€§èƒ½æ³¢åŠ¨ä»…åœ¨Â 0.3%Â ä»¥å†…ã€‚æ›´é‡è¦çš„æ˜¯ï¼Œåœ¨å®Œå…¨å¯¹é½åˆ†è¾¨ç‡è®¾ç½®åï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¾ç„¶ä¿æŒäº†ä¼˜å¼‚çš„æ€§èƒ½ã€‚è¿™å……åˆ†è¯å®äº†æ€§èƒ½çš„æå‡ä¸»è¦å½’å› äºç½‘ç»œç»“æ„çš„æ”¹è¿›ï¼Œè€Œéå®éªŒé…ç½®çš„å·®å¼‚ã€‚
<div align="center">
  <img width="672" height="115" alt="image" src="https://github.com/user-attachments/assets/c03113d5-4521-4f0c-91ea-e38be0759450" />
</div>

### Implementation Details
ä¸ºäº†ç¡®ä¿ç»“æœçš„å¯å¤ç°æ€§ï¼Œæˆ‘ä»¬çš„å®éªŒè®¾ç½®ä¸¥æ ¼å‚ç…§äº† HSNet å’Œ DCAMA çš„å®éªŒæ¡ä»¶ï¼Œå¹¶è¿›è¡Œäº†ç‰¹å®šè°ƒæ•´ï¼šæˆ‘ä»¬é‡‡ç”¨Â Adam ä¼˜åŒ–å™¨ï¼ˆåˆå§‹å­¦ä¹ ç‡è®¾ç½®ä¸ºÂ 1e-4ï¼‰ï¼Œå…±è®­ç»ƒÂ 100 ä¸ª epochÂ ç›´è‡³æ”¶æ•›ã€‚æ­¤å¤–ï¼Œéµå¾ª HSNet çš„è®¾ç½®ï¼Œæˆ‘ä»¬åœ¨æ­¤è®­ç»ƒé˜¶æ®µæœªå¼•å…¥é¢å¤–çš„æ•°æ®å¢å¼ºç­–ç•¥ã€‚æ‰€æœ‰å®éªŒå‡åœ¨ 4 å¼ Â NVIDIA RTX 4090Â GPU ä¸Šå®Œæˆã€‚
è®­ç»ƒè®¾ç½®è§- **Source Code**: The implementation of train can be found in [`train.sh`](./scripts/train.sh). 
æµ‹è¯•è®¾ç½®è§- **Source Code**: The implementation of test can be found in [`test.sh`](./scripts/test.sh). 
å…¶ä½™è¶…å‚æ•°è®¾ç½®è§- **Source Code**: The implementation of config can be found in [`config.py`](./common/config.py). 

### Response to PAAM module
æˆ‘ä»¬ç¡®è®¤Waå’ŒWpæ˜¯é€šè¿‡ç«¯åˆ°ç«¯çš„åå‘ä¼ æ’­è‡ªé€‚åº”å­¦ä¹ å¾—åˆ°çš„ï¼Œè®¾è®¡äº†ä¸€ä¸ªè½»é‡çº§çš„å‚æ•°ç”Ÿæˆç½‘ç»œï¼Œè¯¥å­ç½‘ç»œåŒ…å«å…¨å±€å¹³å‡æ± åŒ–å±‚å’Œä¸¤å±‚MLPï¼ˆLinear -> ReLU -> Linear -> Softmaxï¼‰ã€‚

å¯¹äºå…±äº«å˜æ¢ï¼Œæˆ‘ä»¬ä½¿ç”¨çº¿æ€§å±‚è¿›è¡Œé™ç»´çš„æ—¶å€™ä½¿ç”¨äº†å…±äº«çš„çº¿æ€§å±‚ï¼Œè€Œç”Ÿæˆå„è‡ªå˜æ¢æ—¶ä½¿ç”¨ç‹¬ç«‹çš„çº¿æ€§å±‚ï¼Œå…±äº«æƒé‡é€šè¿‡å‡å°‘å‚æ•°é‡èµ·åˆ°äº†æ­£åˆ™åŒ–ä½œç”¨ï¼Œé˜²æ­¢äº†å°æ ·æœ¬ä»»åŠ¡ä¸­çš„è¿‡æ‹Ÿåˆï¼Œå¼ºåˆ¶å¹…åº¦å’Œç›¸ä½ç‰¹å¾åœ¨ç»Ÿä¸€çš„æ½œç©ºé—´ä¸­å¯¹é½ã€‚

### Cost Analysis of AMAM Calculation
AMAMæ¨¡å—æ˜¯æ— å‚æ•°çš„ï¼Œå…¶è¿ç®—ä¸»è¦æ˜¯ç”±çŸ©é˜µä¹˜æ³•å¾—åˆ°ï¼Œè®¡ç®—å¤æ‚åº¦æ˜¯Oï¼ˆN2ï¼‰
<div align="center">
  <img width="729" height="107" alt="image" src="https://github.com/user-attachments/assets/68bc429a-8520-4baf-b6c8-b9604102277a" />
</div>

å«å™ªå£°æ”¯æŒæ©ç å®éªŒï¼šä¸ºäº†è¯„ä¼°æ¨¡å‹å¯¹ä¸å®Œç¾æ ‡æ³¨çš„é²æ£’æ€§ï¼Œæˆ‘ä»¬é€šè¿‡å¯¹ æ”¯æŒ æ©ç åº”ç”¨å½¢æ€å­¦è†¨èƒ€æ¥æ¨¡æ‹Ÿå™ªå£°ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸åŒå¤§å°çš„æ ¸æ¥æ‰©å±•æ©ç è¾¹ç•Œã€‚è¿™ä¸€è¿‡ç¨‹ä¸å¯é¿å…åœ°å°†èƒŒæ™¯æ‚è´¨å¼•å…¥åˆ°æ”¯æŒç‰¹å¾ä¸­ï¼Œåˆ›é€ äº†ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„åœºæ™¯ã€‚
<div align="center">
  <img width="687" height="151" alt="image" src="https://github.com/user-attachments/assets/d1c860f0-1596-460c-95ea-789cb1352d34" />
</div>

ç”±æ­¤è¡¨å¯ä»¥çœ‹åˆ°å°±ç®—åœ¨è†¨èƒ€ç‡20æ”¯æŒæ©ç å…·æœ‰ä¸¥é‡å™ªå£°æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬çš„æ¨¡å‹ä»ç„¶ä¿æŒä¸€å®šçš„æ€§èƒ½ï¼Œè¯æ˜äº†æˆ‘ä»¬æ¨¡å‹é¢å¯¹å«å™ªå£°æ”¯æŒæ©ç çš„å®éªŒé²æ£’æ€§

### CTSGM and Generalization of the model
We followed the standard protocol by using the template "a photo of a {class}" for text embeddings. Additionally, we explicitly verified the generalization effectiveness of our method through cross-domain experiments transferred from COCO-20i to PASCAL-5i.
æœ¬æ–‡å®éªŒé‡‡ç”¨çš„æ˜¯æ ‡å‡†æ¨¡æ¿ï¼ša photo of a {class},è¿›ä¸€æ­¥æœ¬æ–‡åœ¨è·¨æ•°æ®é›†ä¸Šå®éªŒCOCO-20i to PAscal-5iéªŒè¯å…¶æ³›åŒ–æœ‰æ•ˆæ€§.


<div align="center">
  <img width="610" height="197" alt="image" src="https://github.com/user-attachments/assets/e1562c8b-da58-4333-b60a-5456b2d85937" />
</div>





# Frequency-enhanced Affinity Map Weighted Mask Aggregation for Few-Shot Semantic Segmentation

<div align="center">

<!-- You can add badges here if you have them, e.g., PyTorch version, License -->
<!-- ![PyTorch](https://img.shields.io/badge/PyTorch-%23EE4C2C.svg?style=for-the-badge&logo=PyTorch&logoColor=white) -->

</div>

## ğŸ“– Introduction

This repository contains the implementation of **Frequency-enhanced Affinity Map Weighted Mask Aggregation (FAMANet)** for Few-Shot Semantic Segmentation.

## ğŸ—ï¸ Network Architecture

The overall architecture of our proposed method is shown below:

<div align="center">
  <img width="1485" height="718" alt="Network Architecture" src="https://github.com/user-attachments/assets/0d70bd9b-b4d1-45c9-b0aa-41f1d0f80a1e" />
</div>

---

## ğŸ§© Key Modules

### 1. Phase and Amplitude Attention Module (PAAM)

PAAM is designed to enhance feature representation by utilizing frequency domain information.

- **Source Code**: The implementation of PAAM can be found in [`PhaseandAmplitudeAttention.py`](./PhaseandAmplitudeAttention.py). 

<div align="center">
  <img src="https://github.com/user-attachments/assets/0c070ff6-e029-42f0-a4ae-51cf7d82a6ef" width="700" alt="PAAM Structure">
</div>

#### Visualization of PAAM Effects
Visual comparison showing the effectiveness of the frequency-enhanced attention:

<div align="center">
  <img src="https://github.com/user-attachments/assets/292ded22-2696-48b3-a193-8cd544828303" width="600" alt="PAAM Visualization">
</div>

### 2. Affinity Map Aggregation Module (AMAM)

AMAM utilizes cross-attention mechanisms to aggregate mask weights based on affinity maps.

- **Source Code**: The implementation of AMAM can be found in [`CrossAttention.py`](./CrossAttention.py). 

<div align="center">
  <img src="https://github.com/user-attachments/assets/9a5b1505-7496-4217-952a-501e9bb5b236" width="700" alt="AMAM Structure">
</div>

---
###   DataSet
<div align="center">
  <img width="720" height="750" alt="image" src="https://github.com/user-attachments/assets/f9934672-845b-4ed1-b76d-d47d5afe33c5" />
</div>
<div align="center">
  <img width="722" height="752" alt="image" src="https://github.com/user-attachments/assets/41b72d33-ee1b-4ebb-9a3f-76b75caf60e0" />
</div>



## ğŸš€ Getting Started

### Training
To train the model, please verify the configurations in the script and run:

```bash
bash train.sh

### Testing
To test the model, please verify the configurations in the script and run:

```bash
bash test.sh

